name: Promote-Selected-Model

on:
  workflow_dispatch:
    inputs:
      model_name:
        description: "MLflow model name (e.g., light-logreg)"
        required: true
        default: "light-logreg"
      run_id:
        description: "RUN_ID to promote (copy from MLflow UI)"
        required: true
      reload_method:
        description: "How to refresh serve (rollout|http)"
        required: true
        default: "rollout"

jobs:
  promote:
    runs-on: self-hosted

    env:
      # K8s
      NAMESPACE: mlops
      SERVE_DEPLOY: light-serve
      SERVE_CONTAINER_INDEX: "0"   # serve 컨테이너 인덱스(0이 아니면 바꾸세요)
      SERVE_PORT: "8000"
      SERVE_STAGE: Production       # MODEL_URI는 models:/<MODEL_NAME>/<SERVE_STAGE>

      # MLflow
      MLFLOW_TRACKING_URI: http://mlflow.mlops.svc.cluster.local:5000
      MODEL_NAME: ${{ inputs.model_name }}
      RUN_ID: ${{ inputs.run_id }}

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps (runner side)
        run: pip install --no-cache-dir mlflow-skinny

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'v1.30.0'

      - name: Build in-cluster kubeconfig (runner pod)
        run: |
          set -e
          CACERT=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          SA_TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)
          API="https://${KUBERNETES_SERVICE_HOST}:${KUBERNETES_SERVICE_PORT}"
          kubectl config set-cluster in-cluster --server="${API}" --certificate-authority="${CACERT}" --embed-certs=true
          kubectl config set-credentials sa --token="${SA_TOKEN}"
          kubectl config set-context in-cluster --cluster=in-cluster --user=sa --namespace=${NAMESPACE}
          kubectl config use-context in-cluster

      # 1) 선택 RUN을 Registry로 승격 (기존 promote.py 사용)
      - name: Promote in MLflow (runs:/<RUN_ID>/model)
        run: python promote.py

      # 2) MLflow RUN 태그에서 GHCR 이미지(ref 우선) 결정
      - name: Resolve GHCR image from MLflow RUN tags
        id: resolve_image
        env:
          MLFLOW_TRACKING_URI: ${{ env.MLFLOW_TRACKING_URI }}
          RUN_ID: ${{ env.RUN_ID }}
        run: |
          set -euo pipefail
          python - <<'PY'
          import os, sys, mlflow
          mlflow.set_tracking_uri(os.environ["MLFLOW_TRACKING_URI"])
          run = mlflow.get_run(os.environ["RUN_ID"])
          tags = run.data.tags
          ref    = (tags.get("ghcr.ref")    or "").strip()
          image  = (tags.get("ghcr.image")  or "").strip()
          digest = (tags.get("ghcr.digest") or "").strip()
          tag    = (tags.get("ghcr.tag")    or "").strip()
          if ref:
              out, reason = ref, "ghcr.ref"
          elif image and digest:
              out, reason = f"{image}@{digest}", "image+digest"
          elif image and tag:
              out, reason = f"{image}:{tag}", "image+tag"
          else:
              out, reason = "", "fallback-none"
          print(f"Resolved={out} reason={reason}", file=sys.stderr)
          with open(os.environ["GITHUB_ENV"], "a") as f:
              f.write(f"SERVE_IMAGE={out}\n")
              f.write(f"SERVE_IMAGE_REASON={reason}\n")
          PY
          if [ -z "${SERVE_IMAGE}" ]; then
            echo "::warning ::Could not resolve GHCR image from MLflow tags for RUN_ID=${RUN_ID}. Skipping image patch."
          else
            echo "Using SERVE_IMAGE=${SERVE_IMAGE} (source=${SERVE_IMAGE_REASON})"
          fi

      # 3) 배포 정규화(핵심): replicas, command/args, port name, probes, resources, MODEL_URI
      - name: Normalize serve Deployment (no pip install, proper probes/port/resources)
        run: |
          set -euo pipefail
          DEPLOY="$(kubectl -n "${NAMESPACE}" get deploy -o name | grep "^deployment.apps/${SERVE_DEPLOY}$" || true)"
          if [ -z "${DEPLOY}" ]; then
            echo "❌ Deployment ${SERVE_DEPLOY} not found in ${NAMESPACE}"; exit 1
          fi

          # (A) 복제수 1로 축소(롤링 충돌 방지). 필요하면 나중에 늘리세요.
          kubectl -n "${NAMESPACE}" scale deploy/${SERVE_DEPLOY} --replicas=1

          IDX="${SERVE_CONTAINER_INDEX:-0}"

          # (B) 실행 커맨드 고정: mlflow models serve -m $(MODEL_URI) --host 0.0.0.0 --port 8000 --env-manager local
          kubectl -n "${NAMESPACE}" patch ${DEPLOY} --type='json' -p="[
            {\"op\":\"replace\",\"path\":\"/spec/template/spec/containers/${IDX}/command\",\"value\":[\"mlflow\"]},
            {\"op\":\"replace\",\"path\":\"/spec/template/spec/containers/${IDX}/args\",\"value\":[\"models\",\"serve\",\"-m\",\"$(MODEL_URI)\",\"--host\",\"0.0.0.0\",\"--port\",\"${SERVE_PORT}\",\"--env-manager\",\"local\"]}
          ]"

          # (C) port name=http 보장
          kubectl -n "${NAMESPACE}" patch ${DEPLOY} --type='json' -p="[
            {\"op\":\"add\",\"path\":\"/spec/template/spec/containers/${IDX}/ports\",\"value\":[{\"containerPort\":${SERVE_PORT},\"name\":\"http\"}]}
          ]" || kubectl -n "${NAMESPACE}" patch ${DEPLOY} --type='json' -p="[
            {\"op\":\"replace\",\"path\":\"/spec/template/spec/containers/${IDX}/ports\",\"value\":[{\"containerPort\":${SERVE_PORT},\"name\":\"http\"}]}
          ]"

          # (D) startup/readiness/liveness 프로브 튜닝
          kubectl -n "${NAMESPACE}" patch ${DEPLOY} --type='json' -p='[
            {"op":"replace","path":"/spec/template/spec/containers/'"${IDX}"'/startupProbe","value":{
              "httpGet":{"path":"/ping","port":"http"},
              "initialDelaySeconds":30,
              "periodSeconds":5,
              "timeoutSeconds":3,
              "failureThreshold":120
            }},
            {"op":"replace","path":"/spec/template/spec/containers/'"${IDX}"'/readinessProbe","value":{
              "httpGet":{"path":"/ping","port":"http"},
              "periodSeconds":5,
              "timeoutSeconds":2,
              "failureThreshold":6
            }},
            {"op":"replace","path":"/spec/template/spec/containers/'"${IDX}"'/livenessProbe","value":{
              "httpGet":{"path":"/ping","port":"http"},
              "initialDelaySeconds":60,
              "periodSeconds":10,
              "timeoutSeconds":2,
              "failureThreshold":3
            }}
          ]'

          # (E) 리소스 여유 (Exit 137 방지)
          kubectl -n "${NAMESPACE}" patch ${DEPLOY} --type='json' -p='[
            {"op":"replace","path":"/spec/template/spec/containers/'"${IDX}"'/resources","value":{
              "requests":{"cpu":"200m","memory":"512Mi"},
              "limits":{"cpu":"1","memory":"1Gi"}
            }}
          ]'

          # (F) S3/MinIO 환경 보장 (중복 줄이기; 필요 없는 항목은 빼도 됨)
          kubectl -n "${NAMESPACE}" set env deploy/${SERVE_DEPLOY} \
            MLFLOW_S3_ENDPOINT_URL="http://minio.${NAMESPACE}.svc.cluster.local:9000" \
            AWS_DEFAULT_REGION="us-east-1" \
            AWS_S3_FORCE_PATH_STYLE="true"

          # (G) MODEL_URI 스테이지 통일
          kubectl -n "${NAMESPACE}" set env deploy/${SERVE_DEPLOY} \
            MODEL_URI="models:/${MODEL_NAME}/${SERVE_STAGE}"

      # 4) MLflow로부터 계산된 GHCR 이미지로 컨테이너 이미지 교체
      - name: Patch serve image (from MLflow RUN tags)
        if: ${{ env.SERVE_IMAGE != '' }}
        run: |
          set -e
          DEPLOY=$(kubectl -n "${NAMESPACE}" get deploy -o name | grep "${SERVE_DEPLOY}")
          INDEX=${SERVE_CONTAINER_INDEX:-0}
          kubectl -n "${NAMESPACE}" patch ${DEPLOY} --type='json' -p="[
            {\"op\":\"replace\",\"path\":\"/spec/template/spec/containers/${INDEX}/image\",\"value\":\"${SERVE_IMAGE}\"}
          ]"
          echo "Patched image to ${SERVE_IMAGE}"

      # 5) 롤아웃 재시작/상태 확인
      - name: Rollout restart serve
        if: ${{ inputs.reload_method == 'rollout' || env.SERVE_IMAGE != '' }}
        run: |
          set -e
          kubectl -n "${NAMESPACE}" rollout restart deploy/${SERVE_DEPLOY}
          kubectl -n "${NAMESPACE}" rollout status  deploy/${SERVE_DEPLOY} --timeout=600s
          kubectl -n "${NAMESPACE}" get pods -l app=${SERVE_DEPLOY} -o wide

      # 6) (옵션) HTTP 핫 리로드가 구현돼 있다면
      - name: Call /reload on light-serve (HTTP) [optional]
        if: ${{ inputs.reload_method == 'http' }}
        run: |
          curl -s -X POST http://${{ env.SERVE_DEPLOY }}.${{ env.NAMESPACE }}.svc.cluster.local:${{ env.SERVE_PORT }}/reload || true

