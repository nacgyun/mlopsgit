name: Promote-Selected-Model

on:
  workflow_dispatch:
    inputs:
      model_name:
        description: "MLflow model name (e.g., light-logreg)"
        required: true
        default: "light-logreg"
      run_id:
        description: "RUN_ID to promote (copy from MLflow UI)"
        required: true
      reload_method:
        description: "How to refresh serve (rollout|http)"
        required: true
        default: "rollout"

jobs:
  promote:
    runs-on: self-hosted

    env:
      # K8s 기본값
      NAMESPACE: mlops
      SERVE_DEPLOY: light-serve
      SERVE_CONTAINER_INDEX: "0"      # serve 컨테이너가 첫 번째가 아닐 경우 바꾸세요
      SERVE_PORT: "8000"
      SERVE_STAGE: Production

      # MLflow
      MLFLOW_TRACKING_URI: http://mlflow.mlops.svc.cluster.local:5000
      MODEL_NAME: ${{ inputs.model_name }}
      RUN_ID: ${{ inputs.run_id }}

      # GHCR 풀 권한 필요 시(프라이빗 패키지 등) K8s 쪽 imagePullSecrets를 써야 합니다.
      # 여기서는 런타임에서 별도 인증은 하지 않고, K8s가 이미지 풀 때 시크릿을 사용한다고 가정합니다.

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps (runner side)
        run: pip install --no-cache-dir mlflow-skinny boto3

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'v1.30.0'

      - name: Build in-cluster kubeconfig (runner pod)
        run: |
          set -e
          CACERT=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          SA_TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)
          API="https://${KUBERNETES_SERVICE_HOST}:${KUBERNETES_SERVICE_PORT}"
          kubectl config set-cluster in-cluster --server="${API}" --certificate-authority="${CACERT}" --embed-certs=true
          kubectl config set-credentials sa --token="${SA_TOKEN}"
          kubectl config set-context in-cluster --cluster=in-cluster --user=sa --namespace=${NAMESPACE}
          kubectl config use-context in-cluster

      # 1) 선택된 RUN을 Model Registry로 승격 (당신의 promote.py 그대로 사용)
      - name: Promote in MLflow (runs:/<RUN_ID>/model)
        run: python promote.py

      # 2) MLflow에서 RUN 태그를 읽어 GHCR 이미지(ref/태그) 결정
      - name: Resolve GHCR image from MLflow RUN tags
        id: resolve_image
        env:
          MLFLOW_TRACKING_URI: ${{ env.MLFLOW_TRACKING_URI }}
          RUN_ID: ${{ env.RUN_ID }}
        run: |
          set -euo pipefail
          python - <<'PY'
          import os, sys
          import mlflow

          tracking_uri = os.environ.get("MLFLOW_TRACKING_URI")
          run_id = os.environ["RUN_ID"]

          mlflow.set_tracking_uri(tracking_uri)
          run = mlflow.get_run(run_id)
          tags = run.data.tags

          # 우선순위: ghcr.ref -> (ghcr.image + ghcr.digest) -> (ghcr.image + ghcr.tag) -> fallback
          ref = tags.get("ghcr.ref", "") or ""
          image = tags.get("ghcr.image", "") or ""
          digest = tags.get("ghcr.digest", "") or ""
          tag = tags.get("ghcr.tag", "") or ""

          serve_image = ""
          reason = ""

          if ref:
              serve_image = ref
              reason = "ghcr.ref"
          elif image and digest:
              serve_image = f"{image}@{digest}"
              reason = "image+digest"
          elif image and tag:
              serve_image = f"{image}:{tag}"
              reason = "image+tag"
          else:
              # 마지막 폴백: 사용 중인 기본 serve 이미지(변경하지 않음)
              # 비워두면 이후 스텝에서 스킵
              serve_image = ""
              reason = "fallback-none"

          print(f"Resolved reason={reason} serve_image={serve_image}", file=sys.stderr)
          with open(os.environ["GITHUB_ENV"], "a") as f:
              f.write(f"SERVE_IMAGE={serve_image}\n")
              f.write(f"SERVE_IMAGE_REASON={reason}\n")
          PY

          if [ -z "${SERVE_IMAGE}" ]; then
            echo "::warning ::Could not resolve GHCR image from MLflow tags for RUN_ID=${RUN_ID}. Will not change Deployment image."
          else
            echo "Using SERVE_IMAGE=${SERVE_IMAGE} (source=${SERVE_IMAGE_REASON})"
          fi

      # 3) (선택) MinIO/S3 환경을 serve에 주입
      - name: Ensure S3 env on serve
        run: |
          kubectl -n "${NAMESPACE}" set env deploy/${SERVE_DEPLOY} \
            MLFLOW_S3_ENDPOINT_URL=http://minio.${NAMESPACE}.svc.cluster.local:9000 \
            AWS_DEFAULT_REGION=us-east-1 \
            AWS_S3_FORCE_PATH_STYLE=true
          # (선택) 시크릿 기반 액세스 키가 있을 경우 주입
          # kubectl -n "${NAMESPACE}" patch deploy ${SERVE_DEPLOY} --type='json' -p='[
          #   {"op":"add","path":"/spec/template/spec/containers/0/env/-","value":{"name":"AWS_ACCESS_KEY_ID","valueFrom":{"secretKeyRef":{"name":"minio-creds","key":"accessKey"}}}},
          #   {"op":"add","path":"/spec/template/spec/containers/0/env/-","value":{"name":"AWS_SECRET_ACCESS_KEY","valueFrom":{"secretKeyRef":{"name":"minio-creds","key":"secretKey"}}}}
          # ]'

      # 4) (옵션) serve 엔트리포인트를 강제로 mlflow serve로 바꾸고 싶을 때만 사용
      #    이미 이미지에 준비된 엔트리포인트가 있으면 이 스텝은 생략 가능
      - name: Patch serve entrypoint (optional)
        if: ${{ always() }}  # 필요 없으면 'if: false'로 꺼도 됩니다
        run: |
          set -e
          DEPLOY=$(kubectl -n "${NAMESPACE}" get deploy -o name | grep "${SERVE_DEPLOY}" || true)
          if [ -z "$DEPLOY" ]; then
            echo "Cannot find Deployment containing '${SERVE_DEPLOY}'"; exit 1
          fi
          MODEL_URI="models:/${MODEL_NAME}/${SERVE_STAGE}"
          kubectl -n "${NAMESPACE}" patch ${DEPLOY} --type='json' -p="[ \
            {\"op\":\"replace\",\"path\":\"/spec/template/spec/containers/${SERVE_CONTAINER_INDEX}/command\",\"value\":[\"sh\",\"-c\"]}, \
            {\"op\":\"replace\",\"path\":\"/spec/template/spec/containers/${SERVE_CONTAINER_INDEX}/args\",\"value\":[\"pip install boto3 && mlflow models serve -m ${MODEL_URI} --host 0.0.0.0 --port ${SERVE_PORT} --env-manager local\"]} \
          ]"

      # 5) MLflow에서 얻은 GHCR 이미지로 Deployment 이미지 교체
      - name: Patch serve image (from MLflow RUN tags)
        if: ${{ env.SERVE_IMAGE != '' }}
        run: |
          set -e
          DEPLOY=$(kubectl -n "${NAMESPACE}" get deploy -o name | grep "${SERVE_DEPLOY}")
          # 컨테이너 인덱스 지정으로 이미지 교체 (set image는 이름이 필요해서 json patch가 안전)
          kubectl -n "${NAMESPACE}" patch ${DEPLOY} --type='json' -p="[ \
            {\"op\":\"replace\",\"path\":\"/spec/template/spec/containers/${SERVE_CONTAINER_INDEX}/image\",\"value\":\"${SERVE_IMAGE}\"} \
          ]"
          echo "Patched image to ${SERVE_IMAGE}"

      # 6) 롤링 재시작/상태 확인
      - name: Rollout restart serve
        if: ${{ inputs.reload_method == 'rollout' || env.SERVE_IMAGE != '' }}
        run: |
          set -e
          DEPLOY=$(kubectl -n "${NAMESPACE}" get deploy -o name | grep "${SERVE_DEPLOY}")
          kubectl -n "${NAMESPACE}" rollout restart "${DEPLOY}"
          kubectl -n "${NAMESPACE}" rollout status "${DEPLOY}" --timeout=300s

      # 7) (옵션) HTTP 핫 리로드 (엔드포인트가 구현돼 있다면)
      - name: Call /reload on light-serve (HTTP) [optional]
        if: ${{ inputs.reload_method == 'http' }}
        run: |
          curl -s -X POST http://${{ env.SERVE_DEPLOY }}.${{ env.NAMESPACE }}.svc.cluster.local:${{ env.SERVE_PORT }}/reload || true

