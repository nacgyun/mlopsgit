name: build-and-deploy

on:
  push:
    branches: ["master"]
  workflow_dispatch:

permissions:
  contents: read
  packages: write

env:
  NAMESPACE: mlops
  APP_NAME: myapp
  IMAGE_REPO: "ghcr.io/${{ github.repository }}"
  IMAGE_TAG: "${{ github.sha }}"
  IMAGE: "ghcr.io/${{ github.repository }}:${{ github.sha }}"

jobs:
  build-and-deploy:
    runs-on: self-hosted

    steps:
      - uses: actions/checkout@v4

      # kubectl 설치
      - name: Install kubectl (no-sudo)
        run: |
          set -e
          ver=$(curl -Ls https://dl.k8s.io/release/stable.txt)
          curl -Ls -o "$RUNNER_TEMP/kubectl" "https://dl.k8s.io/release/${ver}/bin/linux/amd64/kubectl"
          chmod +x "$RUNNER_TEMP/kubectl"
          echo "$RUNNER_TEMP" >> "$GITHUB_PATH"

      # kubeconfig 주입 + 확인
      - name: Configure kube access & verify
        run: |
          set -e
          echo "${{ secrets.KUBECONFIG }}" > "$RUNNER_TEMP/kubeconfig"
          echo "KUBECONFIG=$RUNNER_TEMP/kubeconfig" >> "$GITHUB_ENV"
          kubectl version --client
          kubectl get ns || true

      # 네임스페이스 보장
      - name: Ensure namespace exists
        run: |
          kubectl get ns "$NAMESPACE" || kubectl create ns "$NAMESPACE"

      # GHCR 도커 시크릿 (kaniko가 /kaniko/.docker/config.json 사용)
      - name: Ensure GHCR docker secret
        run: |
          kubectl -n "$NAMESPACE" create secret docker-registry ghcr-creds \
            --docker-server=ghcr.io \
            --docker-username="${{ github.actor }}" \
            --docker-password="${{ secrets.GITHUB_TOKEN }}" \
            --docker-email="ci@example.local" \
            --dry-run=client -o yaml | kubectl apply -f -

      # 직전 Kaniko Job 제거
      - name: Cleanup previous Kaniko Job
        run: |
          kubectl -n "$NAMESPACE" delete job kaniko-build --ignore-not-found=true

      # Kaniko Job 적용 (템플릿 치환: __IMAGE__ -> $IMAGE)
      - name: Apply Kaniko Job from template
        run: |
          sed "s|__IMAGE__|${IMAGE}|g" k8s/kaniko-job.yaml.tmpl \
            | kubectl -n "$NAMESPACE" apply -f -

      # 소스 압축 → 1MB 청크 업로드 → 리모트에서 재조립/해제 → .ready 터치
      - name: Upload source (streaming) & release init
        run: |
          set -euo pipefail

          # 1) Job로부터 Pod 이름을 가져올 때까지 대기
          for i in {1..60}; do
            POD=$(kubectl -n "$NAMESPACE" get pods -l job-name=kaniko-build -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)
            [ -n "${POD:-}" ] && break
            sleep 2
          done
          echo "POD=${POD:-<none>}"
          [ -n "${POD:-}" ] || { echo "Pod not found"; exit 1; }

          # 2) init 컨테이너(fetch-src)가 실행 상태일 때까지 대기
          for i in {1..90}; do
            RUNNING=$(kubectl -n "$NAMESPACE" get pod "$POD" -o jsonpath='{.status.initContainerStatuses[?(@.name=="fetch-src")].state.running.startedAt}' 2>/dev/null || true)
            [ -n "$RUNNING" ] && break
            sleep 2
          done
          [ -n "$RUNNING" ] || { echo "fetch-src not running"; kubectl -n "$NAMESPACE" describe pod "$POD" || true; exit 1; }

          # 3) 스트리밍으로 바로 /workspace 에 압축 해제 (중간 파일 없음)
          #    로컬에서 tar.gz 생성 -> exec 표준입력으로 전달 -> 원격에서 즉시 풀기
          tar -C "$GITHUB_WORKSPACE" -czf - . \
            | kubectl -n "$NAMESPACE" exec -i "$POD" -c fetch-src -- sh -lc '
                set -euo pipefail
                rm -rf /workspace/*
                tar -xzf - -C /workspace
                ls -lah /workspace | head -n 50
                touch /workspace/.ready
              '


      # Kaniko 완료 대기 (실패 시 진단)
      - name: Wait for Kaniko build to finish (with diagnostics)
        run: |
          set -e
          if ! kubectl -n "$NAMESPACE" wait --for=condition=Complete job/kaniko-build --timeout=20m; then
            echo "== JOB FAILED: diagnostics =="
            kubectl -n "$NAMESPACE" get job/kaniko-build -o wide || true
            kubectl -n "$NAMESPACE" describe job/kaniko-build || true
            kubectl -n "$NAMESPACE" get pods -l job-name=kaniko-build -o wide || true
            POD=$(kubectl -n "$NAMESPACE" get pods -l job-name=kaniko-build -o jsonpath='{.items[0].metadata.name}')
            kubectl -n "$NAMESPACE" describe pod "$POD" || true
            echo "== INIT(fetch-src) tail =="
            kubectl -n "$NAMESPACE" logs "$POD" -c fetch-src --tail=200 || true
            echo "== KANIKO tail =="
            kubectl -n "$NAMESPACE" logs "$POD" -c kaniko --tail=200 || true
            exit 1
          fi

      # 학습 Job 적용 (템플릿 치환: __IMAGE__ -> $IMAGE)
      - name: Apply training Job (MLflow) from template
        run: |
          kubectl -n "$NAMESPACE" delete job iris-train --ignore-not-found
          sed "s|__IMAGE__|${IMAGE}|g" k8s/iris-train.yaml.tmpl \
            | kubectl -n "$NAMESPACE" apply -f -

      # (옵션) 학습 로그 tail — 실패해도 워크플로 계속
      - name: Tail training logs (best-effort)
        continue-on-error: true
        run: |
          kubectl -n "$NAMESPACE" logs -f job/iris-train -c train --since=1s || true

      # 배포 적용 + 이미지 태그 갱신
      - name: Set image and rollout
        run: |
          set -e
          kubectl -n "$NAMESPACE" apply -f k8s/deploy.yaml
          kubectl -n "$NAMESPACE" set image deploy/${APP_NAME} ${APP_NAME}=${IMAGE} --record
          kubectl -n "$NAMESPACE" rollout status deploy/${APP_NAME} --timeout=5m

