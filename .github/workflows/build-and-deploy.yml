name: Train with MLflow (Runtime image on demand, content-hash tagging)

on:
  workflow_dispatch:
  push:
    branches: [ master ]

# GitHub 발급 GITHUB_TOKEN 권한 (패키지 읽기 허용 + 워크플로우 디스패치)
permissions:
  contents: read
  packages: read
  actions: write

jobs:
  train-build-run:
    runs-on: [self-hosted, k8s]

    env:
      NAMESPACE: mlops
      JOB_BASENAME: train-job
      IMAGE_RUNTIME: ghcr.io/nacgyun/mlopsgit:runtime
      GITHUB_OWNER: nacgyun
      GITHUB_REPO: mlopsgit

      # === Auto-promotion 공통 설정 ===
      PROMOTE_THRESHOLD: "0.97"
      MODEL_NAME: light-logreg     # 실제 MLflow 등록 모델명으로 맞춰서 수정

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install kubectl if missing
        run: |
          set -e
          if ! command -v kubectl >/dev/null 2>&1; then
            ARCH=$(uname -m); case "$ARCH" in x86_64) ARCH=amd64;; aarch64) ARCH=arm64;; esac
            curl -sSL -o kubectl "https://dl.k8s.io/release/$(curl -sSL https://dl.k8s.io/release/stable.txt)/bin/linux/${ARCH}/kubectl"
            chmod +x kubectl && sudo mv kubectl /usr/local/bin/kubectl
          fi
          kubectl version --client=true

      - name: Compute vars
        id: vars
        run: |
          set -euo pipefail
          echo "GIT_SHA=${GITHUB_SHA}" >> $GITHUB_ENV
          echo "SHORT_SHA=$(echo "${GITHUB_SHA}" | cut -c1-12)" >> $GITHUB_ENV
          echo "RUN_ID=${GITHUB_RUN_ID}" >> $GITHUB_ENV
          echo "BUILD_ID=${GITHUB_RUN_NUMBER}-${GITHUB_RUN_ATTEMPT}" >> $GITHUB_ENV
          # lowercase safe forms
          echo "OWNER_LC=$(echo "${GITHUB_OWNER:-$GITHUB_REPOSITORY_OWNER}" | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV
          echo "REPO_LC=$(echo "${GITHUB_REPO:-${GITHUB_REPOSITORY#*/}}" | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV
          echo "NS_LC=$(echo "${NAMESPACE}" | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV
          echo "JOB_NAME=$(echo "${JOB_BASENAME}-${GITHUB_RUN_ID}" | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV

      - name: Detect changes for runtime image (ref only)
        id: changes
        uses: dorny/paths-filter@v3
        with:
          token: ${{ github.token }}
          filters: |
            runtime_image:
              - 'ml/requirements.txt'
              - 'Dockerfile.runtime'
              - 'Dockerfile'

      - name: Check runtime tag by BUILD_KEY
        id: tagcheck
        env:
          GHCR_PAT: ${{ secrets.GHCR_PAT }}
          GITHUB_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail
          if ! command -v jq >/dev/null 2>&1; then
            sudo apt-get update -y >/dev/null 2>&1 || true
            sudo apt-get install -y jq >/dev/null 2>&1 || true
          fi

          OWNER="${GITHUB_OWNER:-nacgyun}"
          REPO="${GITHUB_REPO:-mlopsgit}"
          TOKEN="${GHCR_PAT:-$GITHUB_TOKEN}"

          if [ -f Dockerfile.runtime ] && [ -f ml/requirements.txt ]; then
            BUILD_KEY="$( (cat Dockerfile.runtime; echo; cat ml/requirements.txt) | sha256sum | awk '{print $1}')"
          elif [ -f Dockerfile.runtime ]; then
            BUILD_KEY="$(sha256sum Dockerfile.runtime | awk '{print $1}')"
          else
            BUILD_KEY=""
          fi
          echo "build_key=${BUILD_KEY}" >> "$GITHUB_OUTPUT"

          has_build_tag() {
            curl -fsSL -H "Authorization: Bearer ${TOKEN}" \
              "https://ghcr.io/v2/${OWNER}/${REPO}/tags/list" \
              | jq -e --arg t "runtime-${BUILD_KEY}" '.tags[]? | select(.==$t)' >/dev/null
          }

          NEED_BUILD=false
          if [ -z "${BUILD_KEY}" ]; then
            NEED_BUILD=true
          elif has_build_tag; then
            NEED_BUILD=false
          else
            NEED_BUILD=true
          fi
          echo "need_build=${NEED_BUILD}" >> "$GITHUB_OUTPUT"

      - name: Kaniko runtime-build (render → apply)
        if: steps.tagcheck.outputs.need_build == 'true' && steps.changes.outputs.runtime_image == 'true'
        env:
          KANIKO_JOB_NAME: kaniko-build-${{ github.run_id }}
        run: |
          set -euxo pipefail
          : "${KANIKO_JOB_NAME:?}"; : "${IMAGE_RUNTIME:?}"; : "${GIT_SHA:?}"; : "${NS_LC:?}"

          sed -e "s|__KANIKO_JOB_NAME__|${KANIKO_JOB_NAME}|g" \
              -e "s|__NAMESPACE__|${NS_LC}|g" \
              -e "s|__GITHUB_OWNER__|${OWNER_LC}|g" \
              -e "s|__GITHUB_REPO__|${REPO_LC}|g" \
              -e "s|__GIT_SHA__|${GIT_SHA}|g" \
              -e "s|__BUILD_KEY__|${{ steps.tagcheck.outputs.build_key }}|g" \
            k8s/kaniko-job.yaml.tmpl > /tmp/kaniko-job.yaml

          if grep -Eq '__(KANIKO_JOB_NAME|NAMESPACE|GITHUB_OWNER|GITHUB_REPO|GIT_SHA|BUILD_KEY)__' /tmp/kaniko-job.yaml; then
            echo "? placeholder left in kaniko-job.yaml"; sed -n '1,180p' /tmp/kaniko-job.yaml; exit 1
          fi

          kubectl -n "${NS_LC}" create --dry-run=client -f /tmp/kaniko-job.yaml -o yaml >/dev/null
          echo "----- rendered kaniko-job -----"; sed -n '1,200p' /tmp/kaniko-job.yaml

          kubectl -n "${NS_LC}" delete job "${KANIKO_JOB_NAME}" --ignore-not-found || true
          kubectl -n "${NS_LC}" apply -f /tmp/kaniko-job.yaml
          kubectl -n "${NS_LC}" wait --for=condition=complete --timeout=30m "job/${KANIKO_JOB_NAME}"

          POD=$(kubectl -n "${NS_LC}" get pod -l job-name="${KANIKO_JOB_NAME}" -o jsonpath='{.items[0].metadata.name}')
          kubectl -n "${NS_LC}" logs "$POD" -c kaniko --tail=-1 | egrep -i 'Pushing|Pushed|digest' || true

      - name: Compute IMAGE tag (prefer BUILD_KEY; fallback SHA)
        run: |
          set -e
          RKEY="${{ steps.tagcheck.outputs.build_key }}"
          if [ -z "$RKEY" ]; then RKEY="${GIT_SHA}"; fi
          echo "IMAGE_RUNTIME_KEY=${RKEY}" >> $GITHUB_ENV
          echo "IMAGE_RUNTIME_SHA=${IMAGE_RUNTIME}-${RKEY}" >> $GITHUB_ENV

      - name: Debug ? is GHCR_PAT visible to this run?
        env:
          GHCR_PAT: ${{ secrets.GHCR_PAT }}
        run: |
          set -euo pipefail
          if [ -z "${GHCR_PAT:-}" ]; then
            echo "GHCR_PAT=? (not set in this workflow run)"
            echo "Tip: Repo → Settings → Secrets and variables → Actions → New secret: GHCR_PAT"
          else
            echo "GHCR_PAT=? (present for this run)"
          fi

      # ========= NEW: Preflight ? GHCR_PAT 검증 =========
      - name: Preflight ? verify GHCR_PAT can read packages
        env:
          GHCR_PAT: ${{ secrets.GHCR_PAT }}
          OWNER_LC: ${{ env.OWNER_LC }}
          REPO_LC:  ${{ env.REPO_LC }}
          ACTOR:    ${{ github.actor }}
        run: |
          set -euo pipefail
          if [ -z "${GHCR_PAT:-}" ]; then
            echo "? GHCR_PAT is not set. Create a classic PAT with scope read:packages (and repo if private), then add it to repo secrets."
            exit 1
          fi
          curl -fsSL -u "${ACTOR}:${GHCR_PAT}" https://api.github.com/user >/dev/null || {
            echo "? PAT invalid or SSO not enabled. If your org enforces SSO, click 'Enable SSO' on this PAT."
            exit 1
          }
          TOKEN_JSON=$(curl -fsSL -u "${ACTOR}:${GHCR_PAT}" \
            "https://ghcr.io/token?service=ghcr.io&scope=repository:${OWNER_LC}/${REPO_LC}:pull") || {
            echo "? Failed to get registry token. Ensure package visibility/permission allows this repo/workflow to read."
            exit 1
          }
          echo "$TOKEN_JSON" | jq -re '.token' >/dev/null || {
            echo "? Registry token missing. Check Manage access on the package (or make it public)."
            exit 1
          }
          echo "? GHCR_PAT looks good."

      # ========= NEW: Robust digest resolution =========
      - name: Resolve GHCR digest for runtime image
        id: digest
        env:
          NS_LC: ${{ env.NS_LC }}
          IMAGE_RUNTIME: ${{ env.IMAGE_RUNTIME }}
          IMAGE_RUNTIME_KEY: ${{ env.IMAGE_RUNTIME_KEY }}
          OWNER_LC: ${{ env.OWNER_LC }}
          REPO_LC:  ${{ env.REPO_LC }}
          KANIKO_JOB_NAME: kaniko-build-${{ github.run_id }}
          GHCR_PAT: ${{ secrets.GHCR_PAT }}
          ACTOR:    ${{ github.actor }}
        run: |
          set -euo pipefail

          IMAGE_BASE="${IMAGE_RUNTIME}"                  # ghcr.io/<owner>/<repo>:runtime
          RKEY="${IMAGE_RUNTIME_KEY}"
          IMAGE_TAGGED="${IMAGE_BASE}-${RKEY}"           # ghcr.io/<o>/<r>:runtime-<RKEY>
          REPO_PATH="$(echo "${IMAGE_TAGGED#ghcr.io/}" | cut -d: -f1)"   # <owner>/<repo>
          TAG="$(echo "${IMAGE_TAGGED}" | cut -d: -f2)"                  # runtime-<RKEY>
          echo "[info] Resolving digest for ${IMAGE_TAGGED}"

          # ① Kaniko 로그에서 시도
          DIGEST_FROM_LOG=""
          if kubectl -n "${NS_LC}" get job "${KANIKO_JOB_NAME}" >/dev/null 2>&1; then
            POD=$(kubectl -n "${NS_LC}" get pod -l job-name="${KANIKO_JOB_NAME}" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)
            if [ -n "${POD:-}" ]; then
              DIGEST_FROM_LOG="$(kubectl -n "${NS_LC}" logs "$POD" -c kaniko --tail=-1 2>/dev/null \
                | awk '/digest:[[:space:]]*sha256:/ {print $NF}' \
                | tail -n1 || true)"
            fi
          fi
          if [ -n "${DIGEST_FROM_LOG}" ]; then
            echo "[info] Got digest from Kaniko logs: ${DIGEST_FROM_LOG}"
            DIGEST="${DIGEST_FROM_LOG}"
          else
            echo "[info] Falling back to Registry API with PAT"

            REG_TOKEN="$(curl -fsSL -u "${ACTOR}:${GHCR_PAT}" \
              "https://ghcr.io/token?service=ghcr.io&scope=repository:${REPO_PATH}:pull" \
              | jq -r '.token')"
            if [ -z "${REG_TOKEN}" ] || [ "${REG_TOKEN}" = "null" ]; then
              echo "? Failed to obtain registry token. Check package permission/visibility and PAT scopes (read:packages, SSO)."
              exit 1
            fi

            ACCEPT_HEADER="application/vnd.oci.image.index.v1+json, application/vnd.docker.distribution.manifest.list.v2+json, application/vnd.oci.image.manifest.v1+json, application/vnd.docker.distribution.manifest.v2+json"
            HDRS="$(mktemp)"
            curl -fsSL -D "${HDRS}" -o /dev/null \
              -H "Authorization: Bearer ${REG_TOKEN}" \
              -H "Accept: ${ACCEPT_HEADER}" \
              "https://ghcr.io/v2/${REPO_PATH}/manifests/${TAG}"

            DIGEST="$(awk -F': ' 'tolower($1)=="docker-content-digest"{gsub(/\r/,"");print $2}' "${HDRS}" | tail -n1)"
            if [ -z "${DIGEST}" ]; then
              echo "? Docker-Content-Digest not found. Is the tag present? Check headers below."
              sed -n '1,200p' "${HDRS}" || true
              exit 1
            fi
          fi

          IMAGE_REF="ghcr.io/${REPO_PATH}@${DIGEST}"
          echo "[ok] Resolved ref: ${IMAGE_REF}"
          {
            echo "GHCR_IMAGE=ghcr.io/${REPO_PATH}"
            echo "GHCR_TAG=${TAG}"
            echo "GHCR_DIGEST=${DIGEST}"
            echo "GHCR_IMAGE_REF=${IMAGE_REF}"
          } >> "$GITHUB_ENV"

      - name: Cleanup old train pods (global)
        run: |
          set -euo pipefail
          echo "[cleanup] deleting train pods not Running/ContainerCreating (all previous jobs)"

          PODS=$(kubectl -n "$NS_LC" get pods -l job-name -o jsonpath='{.items[*].metadata.name}')
          if [ -z "$PODS" ]; then
            echo "[cleanup] no train pods found at all"
            exit 0
          fi

          for pod in $PODS; do
            phase=$(kubectl -n "$NS_LC" get pod "$pod" -o jsonpath='{.status.phase}')
            reason=$(kubectl -n "$NS_LC" get pod "$pod" -o jsonpath='{.status.containerStatuses[0].state.waiting.reason}' 2>/dev/null || echo "")

            echo "[inspect] pod=$pod phase=$phase reason=$reason"

            if [ "$phase" = "Running" ] || [ "$reason" = "ContainerCreating" ]; then
              echo "[keep] $pod"
              continue
            fi

            echo "[delete] $pod (phase=$phase reason=$reason)"
            kubectl -n "$NS_LC" delete pod "$pod" --ignore-not-found || true
          done

      - name: Render Train Job manifest
        run: |
          set -euo pipefail
          sed -e "s|__JOB_NAME__|${JOB_NAME}|g" \
              -e "s|__NAMESPACE__|${NS_LC}|g" \
              -e "s|__RUN_ID__|${RUN_ID}|g" \
              -e "s|__BUILD_ID__|${BUILD_ID}|g" \
              -e "s|__GIT_SHA__|${GIT_SHA}|g" \
              -e "s|__IMAGE__|${IMAGE_RUNTIME_SHA}|g" \
              -e "s|__GITHUB_OWNER__|${OWNER_LC}|g" \
              -e "s|__GITHUB_REPO__|${REPO_LC}|g" \
              -e "s|__GHCR_IMAGE__|${GHCR_IMAGE}|g" \
              -e "s|__GHCR_TAG__|${GHCR_TAG}|g" \
              -e "s|__GHCR_DIGEST__|${GHCR_DIGEST}|g" \
              -e "s|__GHCR_IMAGE_REF__|${GHCR_IMAGE_REF}|g" \
            k8s/train-job.yaml.tmpl > /tmp/train-job.yaml

          if grep -qE "__[A-Z0-9_]+__" /tmp/train-job.yaml; then
            echo "? placeholder left in train-job.yaml"
            grep -nE "__[A-Z0-9_]+__" /tmp/train-job.yaml || true
            exit 1
          fi

          echo "----- rendered train-job -----"; sed -n '1,240p' /tmp/train-job.yaml

      - name: Apply Train Job
        run: |
          set -euo pipefail
          kubectl -n "${NS_LC}" delete job "${JOB_NAME}" --ignore-not-found --wait=true || true
          kubectl -n "${NS_LC}" apply -f /tmp/train-job.yaml
          kubectl -n "${NS_LC}" get pods -l job-name="${JOB_NAME}" -o wide || true

      - name: Wait Train → logs
        run: |
          set -euo pipefail
          kubectl -n "${NS_LC}" wait --for=condition=complete --timeout=60m job/${JOB_NAME}
          POD=$(kubectl -n "${NS_LC}" get pod -l job-name="${JOB_NAME}" -o jsonpath='{.items[0].metadata.name}')
          kubectl -n "${NS_LC}" logs "$POD" -c trainer --tail=300 || true
          kubectl -n "${NS_LC}" logs "$POD" -c fetch-src --tail=100 || true

      - name: On failure dump diagnostics
        if: failure()
        run: |
          set -euo pipefail
          POD=$(kubectl -n "${NS_LC}" get pod -l job-name="${JOB_NAME}" -o jsonpath='{.items[0].metadata.name}')
          echo "---- describe job ----"
          kubectl -n "${NS_LC}" describe job "${JOB_NAME}" || true
          echo "---- describe pod ----"
          kubectl -n "${NS_LC}" describe pod "${POD}" || true
          echo "---- init logs ----"
          kubectl -n "${NS_LC}" logs "${POD}" -c fetch-src --tail=200 || true
          echo "---- trainer logs ----"
          kubectl -n "${NS_LC}" logs "${POD}" -c trainer --tail=500 || true

      # ================== NEW: 정확도 파싱 & 자동 프로모션 디스패치 ==================
      - name: Parse accuracy from trainer logs
        id: read_acc
        run: |
          set -euo pipefail
          NS="${NS_LC}"
          JOB="${JOB_NAME}"

          echo "[info] read logs for job=${JOB} ns=${NS}"
          LINE="$(kubectl -n "${NS}" logs -l job-name="${JOB}" --all-containers=true --tail=-1 \
                    | tac | grep -m1 '^\[PROMOTE\] accuracy=' || true)"

          if [ -z "${LINE}" ]; then
            echo "::warning::[PROMOTE] marker not found in logs. Skip auto-promotion."
            echo "acc=NA" >>"$GITHUB_OUTPUT"
            echo "promote=no" >>"$GITHUB_OUTPUT"
            exit 0
          fi

          ACC="$(echo "${LINE}" | sed -n 's/.*accuracy=\([0-9.]\+\).*/\1/p')"
          if [ -z "${ACC}" ]; then
            echo "::warning::Unable to parse accuracy from: ${LINE}"
            echo "acc=NA" >>"$GITHUB_OUTPUT"
            echo "promote=no" >>"$GITHUB_OUTPUT"
            exit 0
          fi

          # ✅ YAML-safe 파이썬 실행 (작은따옴표 heredoc)
          DECIDE="$(ACC="${ACC}" THRESH="${PROMOTE_THRESHOLD}" python - <<'PY'
import os
acc = float(os.environ['ACC'])
thr = float(os.environ['THRESH'])
print("yes" if acc >= thr else "no")
PY
)"
          echo "Parsed accuracy=${ACC}, threshold=${PROMOTE_THRESHOLD} -> promote=${DECIDE}"
          echo "acc=${ACC}" >>"$GITHUB_OUTPUT"
          echo "promote=${DECIDE}" >>"$GITHUB_OUTPUT"

      - name: Auto-dispatch promote-selected-model.yml
        if: ${{ steps.read_acc.outputs.promote == 'yes' }}
        uses: actions/github-script@v7
        with:
          script: |
            const workflowId = 'promote-selected-model.yml';
            // 디스패치는 현재 브랜치 기준 (필요하면 'master'로 고정 가능)
            const ref = (process.env.GITHUB_REF_NAME || (context.ref||'refs/heads/master').replace('refs/heads/','')) || 'master';
            const [owner, repo] = (process.env.GITHUB_REPOSITORY || '${{ env.GITHUB_OWNER }}/${{ env.GITHUB_REPO }}').split('/');

            // run_id는 선택값: 모르면 빈문자열 전달 (promote 워크플로우가 "최신 버전"으로 처리)
            const inputs = {
              model_name: process.env.MODEL_NAME || 'light-logreg',
              run_id: '',                           // (선택) 학습 로그에서 별도 추출 시 채워도 됨
              serve_stage: 'Production'
            };

            core.info(`Dispatching ${workflowId} on ${owner}/${repo}@${ref} with inputs: ${JSON.stringify(inputs)}`);

            await github.rest.actions.createWorkflowDispatch({
              owner,
              repo,
              workflow_id: workflowId,
              ref,
              inputs
            });

            core.info(`Dispatched ${workflowId}.`);

