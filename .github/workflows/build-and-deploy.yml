name: Train with MLflow (Runtime image on demand, always retrain from git)

on:
  workflow_dispatch:
  push:
    branches: [ master ]

jobs:
  train-build-run:
    runs-on: [self-hosted, k8s]

    env:
      NAMESPACE: mlops
      IMAGE_RUNTIME: ghcr.io/${{ github.repository }}:runtime
      TRAIN_JOB_NAME: train-job

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install kubectl if missing
        run: |
          set -e
          if ! command -v kubectl >/dev/null 2>&1; then
            ARCH=$(uname -m); case "$ARCH" in x86_64) ARCH=amd64;; aarch64) ARCH=arm64;; esac
            curl -sSL -o kubectl "https://dl.k8s.io/release/$(curl -sSL https://dl.k8s.io/release/stable.txt)/bin/linux/${ARCH}/kubectl"
            chmod +x kubectl && sudo mv kubectl /usr/local/bin/kubectl
          fi
          kubectl version --client=true

      - name: Set variables
        run: |
          echo "GIT_SHA=${GITHUB_SHA}" >> $GITHUB_ENV
          echo "SHORT_SHA=$(echo ${GITHUB_SHA} | cut -c1-12)" >> $GITHUB_ENV
          echo "REPO=${GITHUB_REPOSITORY}" >> $GITHUB_ENV

      - name: Detect changes for runtime image
        id: changes
        uses: dorny/paths-filter@v3
        with:
          filters: |
            runtime_image:
              - 'Dockerfile.runtime'
              - 'ml/requirements.txt'

      # ===== Kaniko (런타임 이미지 빌드) : 필요한 경우에만 =====
      - name: Render + Apply + Wait Kaniko runtime-build Job
        if: steps.changes.outputs.runtime_image == 'true'
        env:
          KANIKO_JOB_NAME: kaniko-build-${{ github.run_id }}
        run: |
          set -euxo pipefail
          : "${KANIKO_JOB_NAME:?empty}"
          : "${IMAGE_RUNTIME:?empty}"
          : "${GIT_SHA:?empty}"

          echo "KANIKO_JOB_NAME=${KANIKO_JOB_NAME}"
          echo "IMAGE_RUNTIME=${IMAGE_RUNTIME}"
          echo "GIT_SHA=${GIT_SHA}"

          # 1) 렌더
          sed -e "s|__KANIKO_JOB_NAME__|${KANIKO_JOB_NAME}|g" \
              -e "s|__IMAGE__|${IMAGE_RUNTIME}|g" \
              -e "s|__DOCKERFILE__|/workspace/Dockerfile.runtime|g" \
              -e "s|__GIT_SHA__|${GIT_SHA}|g" \
            k8s/kaniko-job.yaml.tmpl > k8s/kaniko-job.yaml

          echo "----- k8s/kaniko-job.yaml (rendered) -----"
          cat k8s/kaniko-job.yaml

          # 2) 플레이스홀더 미치환 체크 → 실패 시 즉시 종료
          if grep -E "__KANIKO_JOB_NAME__|__IMAGE__|__DOCKERFILE__|__GIT_SHA__" k8s/kaniko-job.yaml; then
            echo "❌ Placeholder not replaced. Aborting."; exit 1
          fi

          # 3) 적용 + 대기 + 로그
          kubectl -n "$NAMESPACE" apply -f k8s/kaniko-job.yaml
          kubectl -n "$NAMESPACE" wait --for=condition=complete --timeout=30m job/${KANIKO_JOB_NAME}
          POD=$(kubectl -n "$NAMESPACE" get pod -l job-name="${KANIKO_JOB_NAME}" -o jsonpath='{.items[0].metadata.name}')
          kubectl -n "$NAMESPACE" logs "$POD" --tail=300 || true

      # ===== Train Job (항상 최신 커밋으로 실행) =====
      - name: Render Train Job manifest
        run: |
          set -e
          sed -e "s|__IMAGE__|${IMAGE_RUNTIME}|g" \
              -e "s|__GIT_SHA__|${GIT_SHA}|g" \
            k8s/train-job.yaml.tmpl > k8s/train-job.yaml
          echo "----- k8s/train-job.yaml -----"
          cat k8s/train-job.yaml

      - name: Cleanup previous Train Job
        run: |
          set -e
          kubectl -n "$NAMESPACE" delete job "$TRAIN_JOB_NAME" --ignore-not-found --wait=true || true

      - name: Apply Train Job
        run: |
          set -e
          kubectl -n "$NAMESPACE" apply -f k8s/train-job.yaml
          kubectl -n "$NAMESPACE" get pods -l job-name="$TRAIN_JOB_NAME" -o wide

      - name: Wait Train → logs
        run: |
          set -e
          kubectl -n "$NAMESPACE" wait --for=condition=complete --timeout=60m job/${TRAIN_JOB_NAME}
          POD=$(kubectl -n "$NAMESPACE" get pod -l job-name="${TRAIN_JOB_NAME}" -o jsonpath='{.items[0].metadata.name}')
          kubectl -n "$NAMESPACE" logs "$POD" --tail=300 || true

